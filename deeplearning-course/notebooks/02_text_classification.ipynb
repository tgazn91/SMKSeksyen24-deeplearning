{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üí¨ Lesson 2: AI Baca & Faham Text!\n",
    "\n",
    "**Masa:** 60 minit\n",
    "\n",
    "**Goal:** Buat AI yang boleh detect sama ada review/komen tu positive atau negative!\n",
    "\n",
    "---\n",
    "\n",
    "## ü§î Kenapa Belajar Ni?\n",
    "\n",
    "Korang tau tak:\n",
    "- **Shopee/Lazada** - Auto-detect review bagus atau teruk\n",
    "- **Twitter/X** - Trending topics analysis\n",
    "- **YouTube** - Filter spam comments\n",
    "- **ChatGPT** - Faham apa korang tanya!\n",
    "\n",
    "Semua ni guna **NLP (Natural Language Processing)**! üî•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Macam Mana AI Faham Bahasa?\n",
    "\n",
    "1. **Language Model Pretraining:** Model belajar structure bahasa (grammar, vocabulary)\n",
    "2. **Fine-tuning:** Kita ajar untuk specific task (positive vs negative)\n",
    "\n",
    "Macam orang yang dah tau Bahasa Inggeris, kita just ajar \"ni positive, ni negative\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalau guna Google Colab:\n",
    "# !pip install -Uqq fastai\n",
    "\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download Dataset\n",
    "\n",
    "Kita guna IMDB movie reviews dulu sebab dah ready.\n",
    "\n",
    "Lepas ni kita test dengan **Manglish**! üá≤üáæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset (movie reviews)\n",
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "print(f\"Dataset: {path}\")\n",
    "print(f\"Contents: {path.ls()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baca data\n",
    "df = pd.read_csv(path/'texts.csv')\n",
    "print(f\"Total reviews: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tengok satu contoh review\n",
    "print(\"Contoh review:\")\n",
    "print(df.iloc[0]['text'][:300] + \"...\")\n",
    "print(f\"\\nLabel: {df.iloc[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Sediakan Data\n",
    "\n",
    "### üß† Concept: Tokenization\n",
    "\n",
    "AI tak faham text macam kita. Kena tukar jadi numbers!\n",
    "\n",
    "```\n",
    "\"Best gila movie ni!\" \n",
    "     ‚Üì\n",
    "[\"best\", \"gila\", \"movie\", \"ni\", \"!\"]\n",
    "     ‚Üì\n",
    "[234, 567, 89, 12, 5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat DataLoaders\n",
    "dls = TextDataLoaders.from_df(\n",
    "    df, \n",
    "    path=path, \n",
    "    text_col='text', \n",
    "    label_col='label', \n",
    "    valid_col='is_valid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tengok macam mana text diprocess\n",
    "dls.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üëÄ Notice the Special Tokens!\n",
    "\n",
    "- `xxbos` = Beginning of sentence (start)\n",
    "- `xxmaj` = Next word starts with capital letter\n",
    "- `xxunk` = Unknown word (tak ada dalam vocabulary)\n",
    "\n",
    "Ni cara AI \"encode\" extra information dalam text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Buat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWD-LSTM = sejenis neural network untuk text\n",
    "learn = text_classifier_learner(dls, AWD_LSTM, metrics=accuracy)\n",
    "print(\"Model ready! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Cari Learning Rate Terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate finder - cari \"sweet spot\" untuk training\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: TRAIN! üèãÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train untuk 2 epochs\n",
    "learn.fine_tune(2, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéâ Check Accuracy!\n",
    "\n",
    "Kalau dapat ~85%+, AI kita dah boleh detect sentiment dengan baik!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Tengok Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predictions vs actual\n",
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test dengan Review Sendiri! üéÆ\n",
    "\n",
    "Jom test dengan English dulu, lepas tu cuba Manglish!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dengan custom reviews (English)\n",
    "english_reviews = [\n",
    "    \"This movie was absolutely fantastic! Best film I've seen all year.\",\n",
    "    \"Terrible waste of time. The plot made no sense and acting was awful.\",\n",
    "    \"It was okay, nothing special but not bad either.\"\n",
    "]\n",
    "\n",
    "print(\"=== ENGLISH REVIEWS ===\")\n",
    "for review in english_reviews:\n",
    "    pred, pred_idx, probs = learn.predict(review)\n",
    "    emoji = \"üëç\" if pred == 'positive' else \"üëé\"\n",
    "    print(f\"\\n{emoji} {pred.upper()} ({probs[pred_idx]:.1%})\")\n",
    "    print(f\"   \\\"{review[:50]}...\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üá≤üáæ SEKARANG CUBA MANGLISH!\n",
    "# Model ni trained on English, tapi let's see!\n",
    "\n",
    "manglish_reviews = [\n",
    "    \"Wah best gila movie ni! Highly recommend!\",\n",
    "    \"Boring la cerita ni, waste of time je\",\n",
    "    \"Oklah, not bad but not great also\",\n",
    "    \"Gila babeng sedap makanan dia! Must try!\",\n",
    "    \"Terrible service, waited 1 hour for food. Never again!\",\n",
    "    \"Packaging cantik, delivery laju. 5 stars!\",\n",
    "    \"Barang sampai rosak, seller tak reply. Very bad\"\n",
    "]\n",
    "\n",
    "print(\"=== MANGLISH REVIEWS ===\")\n",
    "for review in manglish_reviews:\n",
    "    pred, pred_idx, probs = learn.predict(review)\n",
    "    emoji = \"üëç\" if pred == 'positive' else \"üëé\"\n",
    "    print(f\"\\n{emoji} {pred.upper()} ({probs[pred_idx]:.1%})\")\n",
    "    print(f\"   \\\"{review}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î Discussion: Boleh Ke AI Faham Manglish?\n",
    "\n",
    "**Try dengan review korang sendiri!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KORANG PUNYA TURN!\n",
    "# Tukar text dalam quotes ni dengan review korang sendiri\n",
    "\n",
    "my_review = \"Tukar text ni dengan review korang!\"\n",
    "\n",
    "pred, pred_idx, probs = learn.predict(my_review)\n",
    "emoji = \"üëç\" if pred == 'positive' else \"üëé\"\n",
    "print(f\"{emoji} AI kata: {pred.upper()}\")\n",
    "print(f\"Confidence: {probs[pred_idx]:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üèÜ CHALLENGE: Review Classifier Competition!\n",
    "\n",
    "### Activity (15 minit)\n",
    "\n",
    "1. **Each student writes 3 reviews** (boleh pasal apa-apa):\n",
    "   - 1 positive review\n",
    "   - 1 negative review  \n",
    "   - 1 tricky/neutral review\n",
    "\n",
    "2. **Test dengan AI** - betul ke prediction dia?\n",
    "\n",
    "3. **Share yang paling funny/surprising!**\n",
    "\n",
    "### Contoh Topics:\n",
    "- Review kantin sekolah\n",
    "- Review game Mobile Legends/PUBG\n",
    "- Review movie/drama Korea\n",
    "- Review kedai makan dekat Shah Alam\n",
    "- Review cikgu favourite (joking! üòÇ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPETITION TIME!\n",
    "# Tampal review korang kat sini\n",
    "\n",
    "student_reviews = [\n",
    "    # Contoh - tukar dengan review korang!\n",
    "    \"Kantin sekolah best! Nasi goreng dia sedap gila\",\n",
    "    \"WiFi sekolah slow sangat, nak submit assignment pun susah\",\n",
    "    \"Cikgu matematik explain okay je, kadang-kadang faham kadang-kadang tak\"\n",
    "]\n",
    "\n",
    "print(\"üèÜ STUDENT REVIEWS COMPETITION üèÜ\\n\")\n",
    "for i, review in enumerate(student_reviews, 1):\n",
    "    pred, pred_idx, probs = learn.predict(review)\n",
    "    emoji = \"üëç\" if pred == 'positive' else \"üëé\"\n",
    "    print(f\"Review #{i}: {emoji} {pred.upper()} ({probs[pred_idx]:.1%})\")\n",
    "    print(f\"   \\\"{review}\\\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üí° Discussion Questions\n",
    "\n",
    "1. **Kenapa AI kadang-kadang silap dengan Manglish?**\n",
    "   - Trained mostly on English\n",
    "   - \"Best gila\" - \"gila\" in English means crazy/bad!\n",
    "   \n",
    "2. **Macam mana Shopee/Lazada boleh detect fake reviews?**\n",
    "   - Same concept - train AI dengan real vs fake examples\n",
    "   \n",
    "3. **Privacy concerns?**\n",
    "   - Shopee tau apa korang suka based on reviews korang baca!\n",
    "\n",
    "---\n",
    "\n",
    "## üåü Real-World Applications\n",
    "\n",
    "| Platform | Use Case |\n",
    "|----------|----------|\n",
    "| Shopee/Lazada | Filter fake reviews, sentiment analysis |\n",
    "| TikTok | Detect harmful comments |\n",
    "| Grab | Analyze driver/rider feedback |\n",
    "| Banks (Maybank etc) | Customer complaint classification |\n",
    "| News sites | Fake news detection |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üè† Homework Ideas\n",
    "\n",
    "1. **Buat Malay Sentiment Classifier**\n",
    "   - Collect reviews dalam Bahasa Malaysia\n",
    "   - Train model baru!\n",
    "\n",
    "2. **Analyze Twitter Trending**\n",
    "   - Scrape tweets pasal trending topic\n",
    "   - What's the overall sentiment?\n",
    "\n",
    "3. **K-pop Fanwar Analysis** üòÇ\n",
    "   - Collect tweets pasal BLACKPINK vs BTS\n",
    "   - Which fandom more positive?\n",
    "\n",
    "---\n",
    "\n",
    "## üî• Bonus: AI Yang Boleh Tulis!\n",
    "\n",
    "Kalau ada masa, cuba buat **Language Model** yang boleh generate text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS: Language Model (text generator)\n",
    "# Uncomment untuk try!\n",
    "\n",
    "# dls_lm = TextDataLoaders.from_df(df, text_col='text', is_lm=True, valid_pct=0.1)\n",
    "# learn_lm = language_model_learner(dls_lm, AWD_LSTM, metrics=[accuracy, Perplexity()])\n",
    "# learn_lm.fine_tune(1)\n",
    "\n",
    "# # Generate text!\n",
    "# print(learn_lm.predict(\"This movie was\", n_words=20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
