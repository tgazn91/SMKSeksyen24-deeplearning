{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸœ Lesson 1: AI Kenal Gambar!\n",
    "\n",
    "**Masa:** 60 minit\n",
    "\n",
    "**Goal:** Buat AI yang boleh kenal perbezaan gambar - collect data sendiri dari internet!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¤” Kenapa Belajar Ni?\n",
    "\n",
    "Korang tau tak:\n",
    "- **Instagram/TikTok filters** - detect muka korang guna AI\n",
    "- **Grab Food** - scan gambar makanan untuk categorize\n",
    "- **CCTV** - detect orang/kereta\n",
    "\n",
    "Semua ni guna **Image Classification**! Jom buat sendiri! ğŸ”¥\n",
    "\n",
    "### ğŸ¯ Hari Ni Kita Belajar:\n",
    "1. **Search** gambar dari internet (guna DuckDuckGo)\n",
    "2. **Download** gambar tu\n",
    "3. **Clean** data (buang gambar rosak)\n",
    "4. **Train** AI model!\n",
    "\n",
    "Sama macam **Jeremy Howard** dalam course.fast.ai! ğŸš€\n",
    "\n",
    "> **Note:** DuckDuckGo sometimes rate limits. If search fails, try: Runtime > Restart runtime, then run again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup - Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Suppress warnings FIRST (before any imports/installs)\nimport warnings\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\n# ============================================================\n# ğŸ“¦ APA ITU PACKAGES & LIBRARIES?\n# ============================================================\n# Package/Library = kod yang orang lain dah tulis untuk kita guna\n# \n# Bayangkan macam ni:\n# - Nak buat rumah, tak perlu buat batu-bata sendiri - beli je!\n# - Nak buat AI, tak perlu tulis semua kod dari zero - guna library!\n#\n# Libraries yang kita guna:\n# - fastai    : Library untuk deep learning (buat AI)\n# - ddgs      : Library untuk search gambar dari DuckDuckGo\n# - gradio    : Library untuk buat web demo\n#\n# !pip install = command untuk download & install packages\n# -Uqq = Update quietly (tak banyak output)\n# ============================================================\n\n!pip install -Uqq fastai ddgs gradio"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import semua yang kita perlukan\nfrom ddgs import DDGS  # New package name (renamed from duckduckgo_search)\nfrom fastcore.all import *\nfrom fastai.vision.all import *\nimport gradio as gr\nimport time\n\nprint(\"âœ… Setup complete! Ready to build AI!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Buat Function untuk Search Gambar\n",
    "\n",
    "DuckDuckGo ni search engine macam Google, tapi more privacy-friendly.\n",
    "\n",
    "Kita buat function untuk search dan download gambar dari internet!\n",
    "\n",
    "**Note:** Kita add retry logic sebab DuckDuckGo kadang-kadang rate limit kalau terlalu banyak request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def search_images(term, max_images=30):\n    \"\"\"\n    Search images dari DuckDuckGo with retry logic\n    \n    Args:\n        term: Apa nak search (contoh: \"nasi lemak\")\n        max_images: Berapa banyak gambar nak dapat\n    \n    Returns:\n        List of image URLs\n    \"\"\"\n    print(f\"ğŸ” Searching for '{term}'...\")\n    \n    for attempt in range(3):  # Try 3 times\n        try:\n            # Use new ddgs package API (query, not keywords)\n            results = DDGS().images(query=term, max_results=max_images)\n            urls = L([r['image'] for r in results])\n            print(f\"   Found {len(urls)} images!\")\n            return urls\n        except Exception as e:\n            if 'Ratelimit' in str(e) or '403' in str(e) or 'forbidden' in str(e).lower():\n                wait_time = (attempt + 1) * 15  # 15s, 30s, 45s\n                print(f\"   â³ Rate limited, waiting {wait_time}s...\")\n                time.sleep(wait_time)\n            else:\n                print(f\"   âš ï¸ Error: {e}\")\n                return L([])\n    \n    print(\"   âŒ Failed after 3 attempts\")\n    return L([])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download Dataset - Malaysian Food! ğŸœ\n",
    "\n",
    "Sekarang kita download gambar untuk **3 jenis makanan Malaysia**:\n",
    "- ğŸš **Nasi Lemak**\n",
    "- ğŸ¥ **Roti Canai**\n",
    "- ğŸœ **Mee Goreng**\n",
    "\n",
    "Untuk setiap makanan, kita download ~20 gambar (cukup untuk demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define makanan yang kita nak classify\nsearches = ['nasi lemak', 'roti canai', 'mee goreng']\n\n# Create main folder\npath = Path('malaysian_food')\n\n# Download gambar untuk setiap jenis makanan\ntotal_downloaded = 0\nfor search_term in searches:\n    # Buat folder untuk setiap makanan\n    folder_name = search_term.replace(' ', '_')\n    dest = path / folder_name\n    dest.mkdir(exist_ok=True, parents=True)\n    \n    # Search dan download gambar (30 images per category)\n    urls = search_images(f\"{search_term} food photo\", max_images=30)\n    \n    if len(urls) > 0:\n        download_images(dest, urls=urls)\n        \n        # Resize images to save space (max 400px)\n        resize_images(dest, max_size=400, dest=dest)\n        \n        downloaded = len(list(dest.glob('*')))\n        total_downloaded += downloaded\n        print(f\"âœ… {search_term} done! ({downloaded} images)\\n\")\n    else:\n        print(f\"âš ï¸ {search_term} - no images found\\n\")\n    \n    # PENTING: Wait 30 saat antara setiap search untuk elak rate limit\n    print(\"â³ Waiting 30s before next search...\")\n    time.sleep(30)\n\nprint(\"=\"*50)\nif total_downloaded > 0:\n    print(f\"ğŸ‰ DOWNLOAD COMPLETE! Total: {total_downloaded} images\")\nelse:\n    print(\"âš ï¸ DuckDuckGo blocked - this sometimes happens in Colab\")\n    print(\"ğŸ’¡ Try: Runtime > Restart runtime, then run again\")\nprint(\"=\"*50)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Clean Data - Buang Gambar Rosak\n",
    "\n",
    "Kadang-kadang gambar yang download tu rosak atau tak boleh dibuka.\n",
    "\n",
    "Fastai ada function `verify_images()` untuk check dan buang gambar yang tak valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and clean images\n",
    "image_files = get_image_files(path)\n",
    "\n",
    "# Clean corrupted images\n",
    "if len(image_files) > 0:\n",
    "    failed = verify_images(image_files)\n",
    "    failed.map(Path.unlink)\n",
    "    print(f\"ğŸ—‘ï¸ Removed {len(failed)} corrupted/invalid images\")\n",
    "    image_files = get_image_files(path)  # Refresh after cleaning\n",
    "\n",
    "print(f\"ğŸ“ Total images: {len(image_files)}\")\n",
    "\n",
    "# Check if we have enough images for training\n",
    "if len(image_files) < 10:\n",
    "    print(\"\\nâš ï¸ Not enough images for training!\")\n",
    "    print(\"ğŸ’¡ Solutions:\")\n",
    "    print(\"   1. Runtime > Restart runtime, then run cells again\")\n",
    "    print(\"   2. Try again later (DuckDuckGo rate limits reset)\")\n",
    "    print(\"   3. Manually download images to the folders\")\n",
    "else:\n",
    "    print(\"âœ… Ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Tengok Sample Gambar\n",
    "\n",
    "Jom tengok gambar yang kita download!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tengok beberapa gambar dari dataset\n",
    "from PIL import Image as PILImg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_files = get_image_files(path)\n",
    "\n",
    "if len(image_files) > 0:\n",
    "    # Show up to 6 sample images\n",
    "    n_show = min(6, len(image_files))\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx in range(n_show):\n",
    "        img = PILImg.open(image_files[idx])\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(image_files[idx].parent.name if image_files[idx].parent.name != 'images' else image_files[idx].name[:20])\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_show, 6):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âš ï¸ No images to display yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Sediakan Data untuk Training (DataLoaders)\n",
    "\n",
    "### ğŸ§  Concept: DataBlock\n",
    "\n",
    "DataBlock ni macam **recipe** untuk prepare data:\n",
    "- `blocks=(ImageBlock, CategoryBlock)` - Input gambar, output category\n",
    "- `get_items=get_image_files` - Ambil semua gambar dari folder\n",
    "- `splitter=RandomSplitter` - Split data untuk train/validation\n",
    "- `get_y=parent_label` - Label = nama folder (nasi_lemak, roti_canai, etc.)\n",
    "- `item_tfms=Resize(192)` - Resize gambar jadi 192x192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Buat DataLoaders untuk Malaysian Food\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(192, method='squish'),\n    # Data augmentation - random flips, rotations, zoom untuk improve accuracy!\n    batch_tfms=aug_transforms(min_scale=0.75)\n).dataloaders(path, bs=8, num_workers=0)  # num_workers=0 for Colab compatibility\n\nprint(\"âœ… DataLoaders created!\")\nprint(f\"   Training batches: {len(dls.train)}\")\nprint(f\"   Validation batches: {len(dls.valid)}\")\nprint(f\"   Categories: {dls.vocab}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jom tengok data kita!\n",
    "dls.show_batch(max_n=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Buat Model (AI Brain! ğŸ§ )\n",
    "\n",
    "### ğŸ§  Concept: Transfer Learning\n",
    "\n",
    "Bayangkan macam ni:\n",
    "- **ResNet18** ni dah \"belajar\" dari **jutaan** gambar\n",
    "- Dah tau macam mana nak kenal edges, shapes, textures\n",
    "- Kita just \"fine-tune\" untuk task kita je\n",
    "\n",
    "Macam **copy homework kawan yang dah pandai**, lepas tu edit sikit! ğŸ˜‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat learner (model + training settings)\n",
    "# Guna resnet18 - smaller & faster untuk demo\n",
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "\n",
    "print(\"ğŸ§  Model created! Ready to train!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: TRAIN! ğŸ‹ï¸\n",
    "\n",
    "Ni part paling best - tengok AI belajar secara real-time!\n",
    "\n",
    "Kita train untuk **3 epochs** (3 rounds through all images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train untuk 3 epochs (no_bar() untuk Colab compatibility)\n",
    "with learn.no_bar():\n",
    "    learn.fine_tune(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ‰ Check Results!\n",
    "\n",
    "Tengok **error_rate** - kalau rendah, meaning AI kita accurate!\n",
    "\n",
    "Contoh: error_rate = 0.15 means **85% accurate**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Tengok Predictions\n",
    "\n",
    "Jom tengok macam mana AI kita perform!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predictions vs actual\n",
    "learn.show_results(max_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix - nak tengok mana yang AI paling confuse\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Show top losses - images yang AI paling confuse\n# Ni best untuk faham kenapa model buat silap!\ninterp.plot_top_losses(6, figsize=(12,8))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### ğŸ§¹ Optional: Clean Data yang Confusing\n\nGuna `ImageClassifierCleaner` untuk review dan delete gambar yang tak betul!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# OPTIONAL: Interactive widget untuk clean dataset\n# Uncomment lines below untuk guna:\n\n# from fastai.vision.widgets import *\n# cleaner = ImageClassifierCleaner(learn)\n# cleaner\n\n# After using cleaner, run this to delete selected images:\n# for idx in cleaner.delete():\n#     cleaner.fns[idx].unlink()\n#     print(f\"Deleted: {cleaner.fns[idx]}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 11: Export Model untuk Deployment\n\nSave model supaya boleh deploy ke web!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Export model untuk deployment\n# pickle_protocol=4 untuk compatibility across Python versions\nlearn.export('malaysian_food_model.pkl', pickle_protocol=4)\n\nprint(\"âœ… Model exported as 'malaysian_food_model.pkl'\")\nprint(\"ğŸ“¥ Download file ni untuk deploy ke Hugging Face!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 12: Buat Web Demo dengan Gradio! ğŸŒ\n\nGradio = buat web interface untuk AI dalam beberapa line code je!\n\nRun cell ni untuk dapat **public link** yang boleh share dengan kawan!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Load exported model\nlearn_inf = load_learner('malaysian_food_model.pkl')\ncategories = learn_inf.dls.vocab\n\ndef classify_food(img):\n    \"\"\"Classify Malaysian food image\"\"\"\n    pred, pred_idx, probs = learn_inf.predict(img)\n    return {categories[i]: float(probs[i]) for i in range(len(categories))}\n\n# Create Gradio interface\ndemo = gr.Interface(\n    fn=classify_food,\n    inputs=gr.Image(type=\"pil\"),\n    outputs=gr.Label(),\n    title=\"ğŸœ Malaysian Food Classifier\",\n    description=\"Upload gambar makanan Malaysia - AI akan kenal sama ada Nasi Lemak, Roti Canai, atau Mee Goreng!\",\n    examples=[[str(f)] for f in get_image_files(path)[:3]]  # Show 3 example images\n)\n\n# Launch with public link!\ndemo.launch(share=True)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 13: Deploy ke Hugging Face Spaces (FREE!) ğŸš€\n\nNak model korang online **24/7**? Deploy ke Hugging Face Spaces!\n\n### Cara Deploy:\n\n1. **Buat akaun** di https://huggingface.co/join (FREE!)\n\n2. **Create New Space:**\n   - Click profile â†’ \"New Space\"\n   - Name: `malaysian-food-classifier`\n   - SDK: **Gradio**\n   - Visibility: **Public**\n\n3. **Upload 3 files:**\n\n**File 1: `app.py`**\n```python\nfrom fastai.vision.all import *\nimport gradio as gr\n\nlearn = load_learner('malaysian_food_model.pkl')\ncategories = learn.dls.vocab\n\ndef classify_food(img):\n    pred, pred_idx, probs = learn.predict(img)\n    return {categories[i]: float(probs[i]) for i in range(len(categories))}\n\ndemo = gr.Interface(\n    fn=classify_food,\n    inputs=gr.Image(type=\"pil\"),\n    outputs=gr.Label(),\n    title=\"ğŸœ Malaysian Food Classifier\",\n    description=\"Nasi Lemak, Roti Canai, atau Mee Goreng?\"\n)\ndemo.launch()\n```\n\n**File 2: `requirements.txt`**\n```\nfastai\ngradio\n```\n\n**File 3: `malaysian_food_model.pkl`** (download dari Colab)\n\n4. **Wait 2-3 minit** untuk build, then DONE! ğŸ‰\n\nYour URL: `https://huggingface.co/spaces/YOUR_USERNAME/malaysian-food-classifier`",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Test dengan Gambar dari Dataset\n",
    "\n",
    "Test AI dengan gambar dari dataset kita!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dengan gambar dari dataset\n",
    "test_files = get_image_files(path)\n",
    "if len(test_files) > 0:\n",
    "    # Pick random image\n",
    "    import random\n",
    "    test_img = PILImage.create(random.choice(test_files))\n",
    "    \n",
    "    # Predict!\n",
    "    pred, pred_idx, probs = learn.predict(test_img)\n",
    "    \n",
    "    print(f\"ğŸ”® AI kata: {str(pred).upper()}\")\n",
    "    print(f\"ğŸ“Š Confidence: {probs[pred_idx]:.1%}\")\n",
    "    test_img.to_thumb(256, 256)\n",
    "else:\n",
    "    print(\"âš ï¸ No test images available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ† CHALLENGE TIME!\n",
    "\n",
    "## Buat Classifier Korang Sendiri!\n",
    "\n",
    "Guna code template di bawah untuk buat classifier untuk topic yang korang suka:\n",
    "\n",
    "### Ideas:\n",
    "1. **Kereta Malaysia** - Proton vs Perodua vs Honda\n",
    "2. **K-pop Groups** - BLACKPINK vs BTS vs TWICE  \n",
    "3. **Football Teams** - JDT vs Selangor vs Perak\n",
    "4. **Animals** - Bird vs Cat vs Dog\n",
    "5. **Your own idea!** - Be creative! ğŸ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TEMPLATE: Buat Classifier Sendiri! ===\n",
    "\n",
    "# 1. Define categories korang\n",
    "my_searches = ['bird photo', 'cat photo', 'dog photo']  # <-- TUKAR NI!\n",
    "\n",
    "# 2. Create folder\n",
    "my_path = Path('my_classifier')\n",
    "\n",
    "# 3. Download images (dengan delay untuk elak rate limit)\n",
    "for search_term in my_searches:\n",
    "    folder_name = search_term.split()[0]  # First word as folder name\n",
    "    dest = my_path / folder_name\n",
    "    dest.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    urls = search_images(search_term, max_images=20)\n",
    "    if len(urls) > 0:\n",
    "        download_images(dest, urls=urls)\n",
    "    \n",
    "    time.sleep(5)  # Wait 5s between searches!\n",
    "    print(f\"âœ… {folder_name} done!\")\n",
    "\n",
    "# 4. Clean data\n",
    "failed = verify_images(get_image_files(my_path))\n",
    "failed.map(Path.unlink)\n",
    "print(f\"\\nğŸ“ Total images: {len(get_image_files(my_path))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create DataLoaders\n",
    "my_dls = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(192)\n",
    ").dataloaders(my_path, bs=32, num_workers=0)  # num_workers=0 for Colab\n",
    "\n",
    "# 6. Show sample\n",
    "my_dls.show_batch(max_n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Train model! (no_bar() for Colab compatibility)\n",
    "my_learn = vision_learner(my_dls, resnet18, metrics=error_rate)\n",
    "with my_learn.no_bar():\n",
    "    my_learn.fine_tune(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Check results\n",
    "my_learn.show_results(max_n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¡ Discussion Questions\n",
    "\n",
    "1. **Kenapa AI kadang-kadang confuse?**\n",
    "   - Gambar dari internet kadang-kadang tak berkualiti\n",
    "   - Background/lighting yang sama\n",
    "   - Need more training data\n",
    "\n",
    "2. **Macam mana nak improve accuracy?**\n",
    "   - Download lebih banyak gambar (100+ setiap category)\n",
    "   - Manually check dan buang gambar yang tak betul\n",
    "   - Train lebih lama (5+ epochs)\n",
    "   - Guna model lebih besar (resnet34, resnet50)\n",
    "\n",
    "3. **Workflow untuk collect custom data:**\n",
    "   ```\n",
    "   1. search_images() â†’ Dapat URLs\n",
    "   2. download_images() â†’ Download ke folder\n",
    "   3. verify_images() â†’ Buang yang rosak\n",
    "   4. DataBlock â†’ Sediakan untuk training\n",
    "   5. vision_learner() â†’ Train!\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Resources\n",
    "\n",
    "- **course.fast.ai** - Full free deep learning course by Jeremy Howard\n",
    "- **Kaggle.com** - Download datasets dan compete\n",
    "\n",
    "---\n",
    "\n",
    "*\"Sekarang korang dah boleh train AI dengan data sendiri dari internet! That's powerful!\"* ğŸš€ğŸ‡²ğŸ‡¾"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}